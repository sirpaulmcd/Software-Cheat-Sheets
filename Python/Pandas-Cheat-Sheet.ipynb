{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Cheat Sheet\n",
    "\n",
    "## Source\n",
    "The following cheat sheet was created using examples from https://www.youtube.com/watch?v=vmEHCJofslg\n",
    "as well as resources from the Pandas Basics cheat sheet from DataCamp.com\n",
    "\n",
    "## Pandas boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is imported for generating nan values\n",
    "import re # Regex imported for regex selection example\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series from list data\n",
    "s = pd.Series([3, -5, 7 , 4], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Create dataframe from dictionary data\n",
    "data = {'Country': ['Belgium','India','Brazil'],\n",
    "        'Capital': ['Brussels','New Delhi','Brasilia'],\n",
    "        'Population': [11190846, 1303171035, 207847528]}\n",
    "\n",
    "df_dict = pd.DataFrame(data, columns=['Country','Capital','Population'])\n",
    "\n",
    "# # Create dataframe using array\n",
    "# df = pd.DataFrame(arr, columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "# Create new dataframe from old dataframe data\n",
    "df_new = df_dict[['Country', 'Capital']]\n",
    "\n",
    "# Create a copy of another dataframe\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "\n",
    "Note that df stands for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV reader command (for comma separated format)\n",
    "    # Indicate which values in used to indicate nans in the csv \n",
    "df = pd.read_csv('pokemon_data.csv', na_values='')\n",
    "\n",
    "# CSV reader command (for csv with no header and dates)\n",
    "    # skiperows=4 Starts converting at row 5\n",
    "    # parse_dates=[0,] Converts dates in column zero\n",
    "    # date_parser=pd.to_datetime Specifies how to parse dates\n",
    "# df = pd.read_csv('temp.csv', header=None, names=['date', 'temp'], skiprows=4, parse_dates=[0,], date_parser=pd.to_datetime)\n",
    "\n",
    "# # Excel reader command (for excel data)\n",
    "# df_xlsx = pd.read_excel('pokemon_data.xlsx')\n",
    "\n",
    "# # Text reader command (for text files with tab as delimiter)\n",
    "# df = pd.read_csv('pokemon_data.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save working data to a csv file\n",
    "    # # 'modified.csv' will be the name of the file\n",
    "    # # index=False line indicates that index will not be included as a column\n",
    "# df.to_csv('modified.csv', index=False)\n",
    "\n",
    "# # Save working data to an excel file\n",
    "# df.to_excel('modified.xlsx', index=False)\n",
    "\n",
    "# # Save working data to a text file (with tab as delimeter)\n",
    "# df.to_csv('modified.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace '?' values with 'NaN'\n",
    "# df = df.replace({'?': 'NaN'})\n",
    "\n",
    "# # Convert dataframe datatypes\n",
    "# df = df.astype('float')\n",
    "\n",
    "# # Generate boolean array of nan values\n",
    "# df.isnull()\n",
    "\n",
    "# # Find the number of nan values in each column\n",
    "# df.isnull().sum()\n",
    "\n",
    "# # Replaces all nan values with average\n",
    "# df.fillna(df.mean())\n",
    "\n",
    "# # Replaces nan values specific columns\n",
    "# data.fillna({'chol': data['chol'].mean(), 'trestbps': data['trestbps'].min()})\n",
    "\n",
    "# # Replace all 12s with 13s and all 13s with 14s in 'count' column\n",
    "# df['count'].replace([12, 13], [13, 14])\n",
    "\n",
    "# # Drop rows containing nan values in specific columns\n",
    "# df.dropna(subset=['chol', 'trestbps'])\n",
    "\n",
    "# # Drops duplicate rows\n",
    "# df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing/Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>Name</th>\n      <th>Type 1</th>\n      <th>Type 2</th>\n      <th>HP</th>\n      <th>Attack</th>\n      <th>Defense</th>\n      <th>Sp. Atk</th>\n      <th>Sp. Def</th>\n      <th>Speed</th>\n      <th>Generation</th>\n      <th>Legendary</th>\n      <th>Total</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bulbasaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>45</td>\n      <td>49</td>\n      <td>49</td>\n      <td>65</td>\n      <td>65</td>\n      <td>45</td>\n      <td>1</td>\n      <td>False</td>\n      <td>318</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ivysaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>60</td>\n      <td>62</td>\n      <td>63</td>\n      <td>80</td>\n      <td>80</td>\n      <td>60</td>\n      <td>1</td>\n      <td>False</td>\n      <td>405</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Venusaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>80</td>\n      <td>82</td>\n      <td>83</td>\n      <td>100</td>\n      <td>100</td>\n      <td>80</td>\n      <td>1</td>\n      <td>False</td>\n      <td>525</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>VenusaurMega Venusaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>80</td>\n      <td>100</td>\n      <td>123</td>\n      <td>122</td>\n      <td>120</td>\n      <td>80</td>\n      <td>1</td>\n      <td>False</td>\n      <td>625</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Charmander</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>39</td>\n      <td>52</td>\n      <td>43</td>\n      <td>60</td>\n      <td>50</td>\n      <td>65</td>\n      <td>1</td>\n      <td>False</td>\n      <td>309</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   #                   Name Type 1  Type 2  HP  Attack  Defense  Sp. Atk  \\\n0  1              Bulbasaur  Grass  Poison  45      49       49       65   \n1  2                Ivysaur  Grass  Poison  60      62       63       80   \n2  3               Venusaur  Grass  Poison  80      82       83      100   \n3  3  VenusaurMega Venusaur  Grass  Poison  80     100      123      122   \n4  4             Charmander   Fire     NaN  39      52       43       60   \n\n   Sp. Def  Speed  Generation  Legendary  Total  count  \n0       65     45           1      False    318      1  \n1       80     60           1      False    405      1  \n2      100     80           1      False    525      1  \n3      120     80           1      False    625      1  \n4       50     65           1      False    309      1  "
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Displays entire dataframe\n",
    "# df\n",
    "\n",
    "# # Displays top 5 rows of dataframe\n",
    "df.head(5)\n",
    "\n",
    "# # Displays bottom 5 rows of dataframe\n",
    "# df.tail(5)\n",
    "\n",
    "# # Displays column headers\n",
    "# df.columns\n",
    "\n",
    "# # Displays the shape of the dataframe (#rows, #cols)\n",
    "# df.shape\n",
    "\n",
    "# # Displays min/max values for each column\n",
    "# df.min()\n",
    "# df.max()\n",
    "\n",
    "# # Displays the mean values for each column\n",
    "# df.mean() \n",
    "\n",
    "# # Displays index, datatype, and memory information\n",
    "# df.info()\n",
    "\n",
    "# # Displays summary statistics for numerical columns\n",
    "# df.describe()\n",
    "\n",
    "# # Displays correlation matrix for columns\n",
    "# df.corr()\n",
    "\n",
    "# # Displays unique values and counts of series (Histogram)\n",
    "# s.value_counts(dropna=False)\n",
    "\n",
    "# # Displays number of non-BA values in each column\n",
    "# df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data by Column Name, Row Index, and Criterion\n",
    "\n",
    "Note: iloc stands for integer location\n",
    "\n",
    "General Format:\n",
    "- iloc\\[rowIndexStart:rowIndexStop, colIndexStart:colIndexStop]\n",
    "- Note that the stop index is NOT included in the selected range\n",
    "- i.e. iloc\\[0:4, 0:3] selects rows of index 0-3 and columns of index 0-2 \n",
    "\n",
    "Return values:\n",
    "- When selecting a single item -> Returns value\n",
    "- When selecting a row/column -> Returns Series\n",
    "- When selecting a table subset -> Returns DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "### SELECTING BY NAME AND INDEX\n",
    "\n",
    "# # Select single column\n",
    "df['Name']\n",
    "\n",
    "# # Select specifc rows of column\n",
    "# df['Name'][0:5] # Selects first 5 rows\n",
    "\n",
    "# # Select multiple columns\n",
    "# df[['Name','Type 1', 'HP']]\n",
    "\n",
    "# # Select single row by index (iloc stands for integer location)\n",
    "# df.iloc[0, :] # Selects first row\n",
    "\n",
    "# # Select multiple rows by index\n",
    "# df.iloc[0:4, :] # Selects first 4 rows\n",
    "\n",
    "# # Select a specific location (rowIndex, colIndex)\n",
    "# df.iloc[2,1] # Selects the data in row index 2, column index 1\n",
    "\n",
    "# # Select a table subset\n",
    "# df[['Name', 'Type 1']].iloc[0:4] # Selects first 4 rows of Name and Type 1 columns\n",
    "# df.iloc[0:4, 0:3] # Equivalent, but less intuitive method\n",
    "\n",
    "#####################################################################################################\n",
    "### SELECTING BY CRITERIA\n",
    "\n",
    "# # Select rows by single criterion using ==\n",
    "# df.loc[df['Type 1'] == 'Grass'] # Selects rows in column 'Type 1' that hold the value of 'Grass'\n",
    "\n",
    "# # Select rows by strings that contain a keyword \n",
    "# df.loc[df['Name'].str.contains('Mega')] # Selects rows that contain 'Mega' in the name\n",
    "\n",
    "# # Select rows by strings that contain a keyword using regex\n",
    "# df.loc[df['Type 1'].str.contains('Fire|Grass', regex=True)] # Selects pokemon of 'Type 1' of Fire or Grass\n",
    "# df.loc[df['Type 1'].str.contains('fire|grass', flags=re.I, regex=True)] # Same as above, ignores case sensitivity\n",
    "# df.loc[df['Name'].str.contains('^pi[a-z]*', flags=re.I, regex=True)] # Selects pokemon with names that start with \"pi\"\n",
    "\n",
    "# # Select rows by multiple criteria (Note that '&' and '|' are to be used rather than 'and' and 'or')'\n",
    "# df.loc[(df['Type 1'] == 'Grass') & (df['Type 2'] == 'Poison') & (df['HP'] > 70)]\n",
    "\n",
    "# Note, if constructing a new DataFrame after selecting multiple criteria, use this on the new df to reset the indexes\n",
    "# df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate through data\n",
    "# for index, row in df.iterrows(): # Iterate through rows (iterrows)\n",
    "#     print(index, row['Name'])    # For each, print index and value under column 'Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "\n",
    "Default sort format:\n",
    "- Letters get sorted alphabetically\n",
    "- Numbers get sorted sorts numbers ascending order\n",
    "\n",
    "Note: Python sorts capitalized words before lowercase words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort series\n",
    "# s.sort_values(ascending=True)\n",
    "\n",
    "# # Sort column of dataframe\n",
    "# df.sort_values('Name', ascending=True) # Ascending is true by default, change this to reverse sort order\n",
    "\n",
    "# # Sort column with sorted subcolumn\n",
    "# # This method sorts by 'HP' then sorts by 'Type 1' such that the pokemon are sorted by type and each type is sorted by HP. \n",
    "# # Note: Change the numbers in ascending=[1,1] to 0 for rows that you want to reverse sort\n",
    "# df.sort_values(['Type 1', 'HP'], ascending=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data\n",
    "\n",
    "When manipulating data, it is a good idea to export to CSV as you go.\n",
    "This way, you can reload a previous version in case you mess up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "### ARRAY MATH\n",
    "\n",
    "# # Math operations on dataframe\n",
    "# # Convert temp data from F to C (assuminng array holds temp values)\n",
    "# df = (9/5) * df + 32\n",
    "\n",
    "# # Sum two dataframes of same shape\n",
    "# df + df2\n",
    "\n",
    "# # Map a function to each column (labda)\n",
    "# f = lambda x: x.max() - x.min()\n",
    "# df.apply(f)\n",
    "\n",
    "#####################################################################################################\n",
    "### ADDING/REMOVING/REORGANIZING COLUMNS\n",
    "\n",
    "# # Add a new nan column to the table\n",
    "# df['Total'] = np.nan\n",
    "\n",
    "# # Add a new column that is the sum of other other numerical columns\n",
    "# df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['Sp. Atk'] + df['Sp. Def'] + df['Speed']\n",
    "\n",
    "# # Drop a column from the table\n",
    "# df = df.drop(columns=['Total'])\n",
    "\n",
    "# # Reorder columns in the table\n",
    "# df = df[['Total', 'HP', 'Defense']] # Overwrites with new dataframe in desired order\n",
    "\n",
    "# # Bin age into 3 categories\n",
    "# # Asking qcut to return a subset of ages, with 3 unique columns, column labels young middle old\n",
    "# data['agegroup'] = pd.qcut(data['age'], 3, labels=['young', 'middle', 'old'] )\n",
    "\n",
    "# # Bin 'chol' column into quantiles\n",
    "# data['chol_quantiles'] = pd.qcut(data['chol'], [0, 0.3, 0.7, 1.0], labels=['low', 'mid', 'high'])\n",
    "\n",
    "#####################################################################################################\n",
    "### CONDITIONAL CHANGES\n",
    "\n",
    "# # Change all 'Fire' type pokemon in column 'Type 1' to 'Flamer'\n",
    "# df.loc[df['Type 1'] == 'Fire', 'Type 1'] = 'Flamer'\n",
    "\n",
    "# # Change all pokemon of type 'Fire' in 'Type 1' to legendary\n",
    "# df.loc[df['Type 1'] == 'Fire', 'Legendary'] = True\n",
    "\n",
    "# # If total > 500, change Generation and Legendary to 'TEST VALUE'\n",
    "# df.loc[df['Total'] > 500, ['Generation', 'Legendary']] = 'TEST VALUE'\n",
    "\n",
    "# # If total > 500, change generation to 'Test 1' and legendary to 'Test 2'\n",
    "# df.loc[df['Total'] > 500, ['Generation','Legendary']] = ['Test 1', 'Test 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Type 1  Type 2  \nBug     Electric     2\n        Fighting     2\n        Fire         2\n        Flying      14\n        Ghost        1\n                    ..\nWater   Ice          3\n        Poison       3\n        Psychic      5\n        Rock         4\n        Steel        1\nName: count, Length: 136, dtype: int64"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get averages for all stat columns according to 'Type 1'\n",
    "# # Eg. You could see which pokemon type had highest average of each stat\n",
    "# df.groupby(['Type 1']).mean()\n",
    "\n",
    "# # Same as above but sorts by defense\n",
    "# df.groupby(['Type 1']).mean().sort_values('Defense', ascending=False)\n",
    "\n",
    "# # Get sum for all stat columns according to 'Type 1'\n",
    "# df.groupby(['Type 1']).sum()\n",
    "\n",
    "# # Get count of all pokemon in each type (Did you know there were 69 bug pokemon?)\n",
    "df['count'] = 1 # Creates new column called 'count' initialized with 1s \n",
    "# Count the number of rows in 'Type 1' that have a value in column 'count'\n",
    "df.groupby(['Type 1']).count()['count']\n",
    "\n",
    "## Can see the number of pokemon in each type subset\n",
    "df.groupby(['Type 1', 'Type 2']).count()['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import this to create a new category type\n",
    "# from pandas.api.types import CategoricalDtype \n",
    "\n",
    "# # Creating new category types. ordered = True means the given argument order should be the heirarchical order used\n",
    "# cat_type = CategoricalDtype(categories=['disagree', 'agree', 'strongly agree'], ordered=True)\n",
    "\n",
    "# # Convert to user defined datatype \n",
    "# df2['parks'] = df2['parks'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV From Web Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url string with variables station, year and month\n",
    "    # Timeframe\n",
    "    # 1 = hourly, 2 = daily (ignores the month, just gives daily data for the entire year (365 rows))\n",
    "url_template = \"https://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv&stationID={station}&Year={year}&Month={month}&Day=14&timeframe=1&submit=Download+Data\"\n",
    "\n",
    "# Replace variables in string with actual values\n",
    "    # station = 2205 is at the Calgary Airport (2205 up to July 2012, 50430 for July 2012 - present)\n",
    "url = url_template.format(station=2205, year=2001, month=5) \n",
    "\n",
    "# Read data from URL into dataframe, use headers and set Date/Time column as index\n",
    "weather_data = pd.read_csv(url, index_col='Date/Time', parse_dates=True) \n",
    "\n",
    "# 27 total columns, but note: some columns don't have any data (N/A)\n",
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Large Datasets\n",
    "\n",
    "Sometimes data is so large it has to be processed in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new empty dataframe with the same column names\n",
    "# new_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# # Pass 5 rows at a time into memory and process\n",
    "# for df in pd.read_csv('modified.csv', chunksize=5):\n",
    "#     results = df.groupby(['Type 1']).count()\n",
    "#     # Concatenate each chunk of results into the new dataframe\n",
    "#     new_df = pd.concat([new_df, results])"
   ]
  }
 ]
}